{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Clone github repo to have access to data files."
      ],
      "metadata": {
        "id": "5cIkMDLZXNhQ"
      },
      "id": "5cIkMDLZXNhQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Hananxx/SentimentAnalysisPromptExp.git"
      ],
      "metadata": {
        "id": "iQX7G_GuXHOc"
      },
      "id": "iQX7G_GuXHOc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "46a7dabf",
      "metadata": {
        "id": "46a7dabf"
      },
      "source": [
        "### Install needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef91428",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "1ef91428",
        "outputId": "7b3c18ac-5a47-4bb0-928e-9226f576d298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pandas accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889fa6a5",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "889fa6a5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set root path for accessing repo files"
      ],
      "metadata": {
        "id": "AQq4LPeJT4FR"
      },
      "id": "AQq4LPeJT4FR"
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"SentimentAnalysisPromptExp/\""
      ],
      "metadata": {
        "id": "T-xyXWocVFvw"
      },
      "id": "T-xyXWocVFvw",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3e848bad",
      "metadata": {
        "id": "3e848bad"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "02589b3c",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "02589b3c",
        "outputId": "fedc6fc5-d155-4571-8e36-45231f0fdf74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence  label\n",
            "0  package file invalid i had my phone on factory...      2\n",
            "1  iffy nice clean app but sometimes it works and...      2\n",
            "2                        cool just freezes everytime      2\n",
            "3  network error! suddenly after downloading an u...      2\n",
            "4  annoying it let me choose the pictures i want ...      2\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(root + 'data/app.csv')\n",
        "print(df.head())  # Inspect the first few rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load prompts"
      ],
      "metadata": {
        "id": "jplWkzR9Xnyw"
      },
      "id": "jplWkzR9Xnyw"
    },
    {
      "cell_type": "code",
      "source": [
        "  with open(root + 'prompts/zero-shot-prompt-template.json', 'r') as f:\n",
        "      templates = json.load(f)\n",
        "  print(templates)  # View the loaded templates"
      ],
      "metadata": {
        "id": "2NeiQrHnXqZ3",
        "outputId": "55662c77-e6ee-4484-d18b-722398631051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2NeiQrHnXqZ3",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'vicuna-0': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: Please perform Sentiment Classification task. Given the sentence from {}, assign a sentiment label from ['negative', 'neutral', 'positive']. Return label only without any other text.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'vicuna-jira-0': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: Please perform Sentiment Classification task. Given the sentence from {}, assign a sentiment label from ['negative', 'positive']. Return label only without any other text.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'llama2-0': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nPlease perform Sentiment Classification task. Given the sentence from {}, assign a sentiment label from ['negative', 'neutral', 'positive']. Return label only without any other text.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\", 'llama2-jira-0': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nPlease perform Sentiment Classification task. Given the sentence from {}, assign a sentiment label from ['negative', 'positive']. Return label only without any other text.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\", 'vicuna-1': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: Please categorize the sentiment expressed in the following sentence from {} as either (1) positive, (2) neutral, or (3) negative.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'vicuna-jira-1': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: Please categorize the sentiment expressed in the following sentence from {} as either (1) positive or (2) negative.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'llama2-1': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nPlease categorize the sentiment expressed in the following sentence from {} as either (1) positive, (2) neutral, or (3) negative.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\", 'llama2-jira-1': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nPlease categorize the sentiment expressed in the following sentence from {} as either (1) positive or (2) negative.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\", 'vicuna-2': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: I will give you a sentence from {}. You need to reply with the sentiment expressed in the following sentence, either (1) positive, (2) neutral, or (3) negative.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'vicuna-jira-2': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\nUSER: I will give you a sentence from {}. You need to reply with the sentiment expressed in the following sentence, either (1) positive or (2) negative.\\nASSISTANT: Sure!</s>\\nUSER: Sentence: {}\\nASSISTANT:\", 'llama2-2': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nI will give you a sentence from {}. You need to reply with the sentiment expressed in the following sentence, either (1) positive, (2) neutral, or (3) negative.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\", 'llama2-jira-2': \"<s>[INST] <<SYS>>\\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\\n<</SYS>>\\nI will give you a sentence from {}. You need to reply with the sentiment expressed in the following sentence, either (1) positive or (2) negative.\\n[/INST]\\nSure!\\n</s><s>[INST]\\nSentence: {}\\nLabel:\\n[/INST]\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Vicuna"
      ],
      "metadata": {
        "id": "ALn1XBrNYLqB"
      },
      "id": "ALn1XBrNYLqB"
    },
    {
      "cell_type": "code",
      "source": [
        "  # For GPU acceleration if available\n",
        "  device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "  # Load tokenizer and model (this may take time on first run)\n",
        "  tokenizer = AutoTokenizer.from_pretrained('lmsys/vicuna-13b-v1.5')\n",
        "  model = AutoModelForCausalLM.from_pretrained('lmsys/vicuna-13b-v1.5', torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
        "  model.to(device)\n",
        "\n",
        "  # Create a text generation pipeline\n",
        "  vicuna_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer, device=device)"
      ],
      "metadata": {
        "id": "MpmjqakgYPEu",
        "outputId": "fa8ec268-f415-417a-fe80-788eb8187952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "id": "MpmjqakgYPEu",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3461280715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For GPU acceleration if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load tokenizer and model (this may take time on first run)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lmsys/vicuna-13b-v1.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}